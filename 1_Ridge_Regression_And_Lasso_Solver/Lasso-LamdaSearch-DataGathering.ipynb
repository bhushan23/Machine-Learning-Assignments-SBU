{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fDF = pd.read_csv('Data/featureTypes.txt', names=['featureID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n",
      "flavors raspberries cherries\n"
     ]
    }
   ],
   "source": [
    "print fDF.shape\n",
    "print fDF['featureID'][0]\n",
    "n = 10000\n",
    "d = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247847\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.read_csv('Data/trainData.txt', names = ['instanceID', 'featureID', 'value'], sep=' ')\n",
    "YDF = pd.read_csv('Data/trainLabels.txt', names = ['label'])\n",
    "valXDF = pd.read_csv('Data/valData.txt', names = ['instanceID', 'featureID', 'value'], sep=' ')\n",
    "valYDF = pd.read_csv('Data/valLabels.txt', names = ['label'])\n",
    "print trainDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "3000\n",
      "3000\n",
      "[ 0.38427511  0.18589934  0.59789612 ...,  0.83150823  0.28715457\n",
      "  0.78962321]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(d)  #random.uniform(low=0.0, high=1.0,size = (d,))\n",
    "B = 0 #np.zeros(n)\n",
    "TempBArray = np.ones(n)\n",
    "print W.shape\n",
    "#print TempBArray\n",
    "print np.count_nonzero(W)\n",
    "print len(W)\n",
    "print W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceID</th>\n",
       "      <th>featureID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instanceID  featureID  value\n",
       "0           1         13  0.209\n",
       "1           1         83  0.209\n",
       "2           1        228  0.209\n",
       "3           1        242  0.209\n",
       "4           1        371  0.209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tDF = csr_matrix(trainDF) \n",
    "#print tDF[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf = pd.SparseDataFrame(tDF)\n",
    "#print sdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will lead to negative index if re-running\n",
    "trainDF['instanceID'] -= 1\n",
    "trainDF['featureID'] -= 1\n",
    "sMat = csr_matrix((trainDF['value'], (trainDF['featureID'], trainDF['instanceID'])))\n",
    "valXDF['instanceID'] -= 1\n",
    "valXDF['featureID'] -= 1\n",
    "valX = csr_matrix((valXDF['value'], (valXDF['featureID'], valXDF['instanceID'])))\n",
    "Y = YDF['label'].as_matrix().transpose()\n",
    "#print Y.shape\n",
    "valY = valYDF['label'].as_matrix().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728 0.0\n"
     ]
    }
   ],
   "source": [
    "#print sMat.shape\n",
    "#print sMat.todense()\n",
    "print sMat.max(), sMat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sMat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 10000)\n"
     ]
    }
   ],
   "source": [
    "X = sMat.copy()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print len(W.nonzero())\n",
    "print len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271.869651\n"
     ]
    }
   ],
   "source": [
    "def initLamda(X, Y):\n",
    "    YNorm = Y - float(Y.sum())/((float)(Y.shape[0]))\n",
    "    return 2 * (abs(X * YNorm).max())\n",
    "    \n",
    "print initLamda(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.731852]\n",
      " [ 2.660682]\n",
      " [ 1.581472]\n",
      " ..., \n",
      " [ 1.564942]\n",
      " [ 2.31796 ]\n",
      " [ 1.5809  ]]\n"
     ]
    }
   ],
   "source": [
    "t = X.copy()\n",
    "t.data **= 2\n",
    "At = 2*t.sum(axis = 1)\n",
    "print At"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "redFact = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to convergence condition\n",
    "\n",
    "def rmse(input1, input2):\n",
    "    out = input1 - input2\n",
    "    #print out\n",
    "    out **= 2\n",
    "    out /= len(out)\n",
    "    error = out.sum()\n",
    "    return math.sqrt(error)\n",
    "\n",
    "\n",
    "class Lasso:\n",
    "    def __init__(self, X, Y, W, B, Lamda):\n",
    "        self.X = X.copy()\n",
    "        self.Y = Y.copy()\n",
    "        self.W = W #.copy()  # Remove this copy later\n",
    "        self.B = B #.copy()\n",
    "        t = X.copy()\n",
    "        t.data **= 2\n",
    "        self.A = 2*t.sum(axis = 1)\n",
    "        self.Lamda = Lamda\n",
    "        self.delta = 0.001\n",
    "        # Stores Lamda and respective RMSE\n",
    "        self.trainrmse = []\n",
    "        self.trainlamda = []\n",
    "        self.valrmse = []\n",
    "        self.vallamda = []\n",
    "        self.NonZero = []\n",
    "        \n",
    "    def loss(self):\n",
    "        return ((self.X.transpose() * self.W + self.B - self.Y) ** 2).sum() + self.Lamda * (abs(self.W)).sum()\n",
    "        \n",
    "    def fit(self):\n",
    "        # Lamda = initLamda(self.X, self.Y)\n",
    "        \n",
    "        #print X.shape, W.shape\n",
    "        #for epoch in range(100):\n",
    "        oldLoss = self.loss()+2\n",
    "        newLoss = self.loss()\n",
    "        print 'Lamda: ', self.Lamda\n",
    "        while oldLoss - newLoss > self.delta:\n",
    "        #for i in range(1000):\n",
    "            #print sMat.transpose() * W\n",
    "            # 4.1.1\n",
    "            #print t1[:5], t1.shape\n",
    "            #print t1.shape, B.shape, Y.shape\n",
    "            XTW = (self.X.transpose() * self.W)\n",
    "            R = self.Y - (self.X.transpose() * self.W) - self.B\n",
    "            \n",
    "            # 4.1.2\n",
    "            BOld = self.B\n",
    "            self.B = np.full(n, (R + self.B).sum() / n) \n",
    "            #print self.B\n",
    "            #print self.B.shape\n",
    "            #self.B = (self.Y - XTW).sum() / n\n",
    "            #print B.shape\n",
    "            # 4.1.3\n",
    "            R =  R + BOld - self.B\n",
    "            #print 'RSHAPE', R.shape\n",
    "            #print 'R', R\n",
    "            #R = self.Y - (XTW + self.B)\n",
    "            #print R.shape\n",
    "            #print R[:5]\n",
    "            # R = R.reshape(-1)\n",
    "            for ik in range(0, d):\n",
    "                # 4.1.4\n",
    "                #ik = 0\n",
    "                t = (self.X[ik].transpose() * self.W[ik]).toarray().reshape(-1)\n",
    "                #print t\n",
    "                #print t.shape\n",
    "                #print R.shape\n",
    "                Ck = 2*( self.X[ik] * (R + t)).sum()\n",
    "                #print 'CK:', Ck\n",
    "                # Update Weight\n",
    "                WkOld = self.W[ik]\n",
    "                #print 'OW: ', WkOld\n",
    "                if Ck < -self.Lamda:\n",
    "                    self.W[ik] = (Ck + self.Lamda) / self.A[ik]\n",
    "                elif Ck > self.Lamda:\n",
    "                    self.W[ik] = (Ck - self.Lamda) / self.A[ik]\n",
    "                else:\n",
    "                    self.W[ik] = 0\n",
    "                #print 'W: ', WkOld, self.W[ik]\n",
    "                #print W[ik]\n",
    "                # 4.1.5\n",
    "                # print self.W[ik], WkOld\n",
    "                #print X[ik].toarray().reshape(-1).shape, R.shape\n",
    "                R = R + self.X[ik].toarray().reshape(-1) * (WkOld - self.W[ik])\n",
    "                #R = self.Y - (self.X.transpose() * self.W) + self.B\n",
    "            oldLoss = newLoss\n",
    "            newLoss = self.loss()\n",
    "            #print oldLoss, newLoss, oldLoss - newLoss\n",
    "            print 'LOSS:' , newLoss\n",
    "            # End of feature vector iterator\n",
    "    \n",
    "    def saveModel(self, filename):\n",
    "        pickle.dump(self, open( filename, \"wb\" ))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (X.transpose() * self.W + np.full(X.transpose().shape[0], self.B))\n",
    "    \n",
    "    def chooseCorrectLamda(self, delta = -1):\n",
    "        oldLamda = self.Lamda\n",
    "        if delta != -1:\n",
    "            self.delta = delta\n",
    "        self.fit()\n",
    "        \n",
    "        newRMSE = rmse(self.predict(self.X), self.Y)\n",
    "        #self.TrainInfo.append([self.Lamda, newRMSE])\n",
    "        self.trainrmse.append(newRMSE)\n",
    "        self.trainlamda.append(self.Lamda)\n",
    "        valRMSE = rmse(self.predict(valX), valY)\n",
    "        self.valrmse.append(valRMSE)\n",
    "        self.vallamda.append(self.Lamda)\n",
    "        oldRMSE = valRMSE\n",
    "        #print W\n",
    "        #self.ValInfo.append([self.Lamda, valRMSE])\n",
    "        self.NonZero.append((self.W != 0.0).sum())\n",
    "        print 'Lamda: ', self.Lamda, 'RMSE: ', newRMSE, 'Val RMSE:' , valRMSE\n",
    "        \n",
    "        while self.Lamda >= 3: #oldRMSE >= valRMSE:\n",
    "            oldLamda = self.Lamda\n",
    "            self.Lamda /= redFact\n",
    "            self.fit()\n",
    "            oldRMSE = valRMSE\n",
    "            #self.TrainInfo.append([self.Lamda, newRMSE])\n",
    "            newRMSE = rmse(self.predict(self.X), self.Y)\n",
    "            self.trainrmse.append(newRMSE)\n",
    "            self.trainlamda.append(self.Lamda)\n",
    "            valRMSE = rmse(self.predict(valX), valY)\n",
    "            #self.ValInfo.append([self.Lamda, valRMSE])\n",
    "            self.valrmse.append(valRMSE)\n",
    "            self.vallamda.append(self.Lamda)\n",
    "            self.NonZero.append(np.count_nonzero(self.W))\n",
    "            #self.NonZero.append(self.W.toarray().count_nonzero())\n",
    "            print 'Lamda: ', self.Lamda, 'RMSE: ', newRMSE, 'Val RMSE:' , valRMSE\n",
    "            self.saveModel('optimal_saved_Model')\n",
    "            \n",
    "def loadModel(filename):\n",
    "    return pickle.load(open(filename, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = loadModel('./finalData/savedModel')\n",
    "newModel.Lamda = 2.48\n",
    "L = newModel.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 740 2585  439 ...,  992 2664  973]\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 features\n",
    "m = L.argsort()\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2468  933 1412 1835  811  358 2544  992 2664  973]\n",
      "-11.1605322336\n",
      "-6.94091162035\n",
      "-6.57564610837\n",
      "-6.10839472434\n",
      "-5.67840297861\n",
      "-5.62164283319\n",
      "-5.56562977712\n",
      "-5.43287124647\n",
      "-5.35869477388\n",
      "-5.06839904746\n"
     ]
    }
   ],
   "source": [
    "top10 = m[-10:]\n",
    "print top10\n",
    "less10 = m[:10]\n",
    "#for i in less10:\n",
    "#    print L[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamda:  2.48\n",
      "LOSS: 33349.4423971\n",
      "LOSS: 33244.8943273\n",
      "LOSS: 33218.2413185\n",
      "LOSS: 33208.6869985\n",
      "LOSS: 33203.9299137\n",
      "LOSS: 33201.0801947\n",
      "LOSS: 33198.9182534\n",
      "LOSS: 33196.9764207\n",
      "LOSS: 33195.0892598\n",
      "LOSS: 33193.1888694\n",
      "LOSS: 33191.2524476\n",
      "LOSS: 33189.2828108\n",
      "LOSS: 33187.2991982\n",
      "LOSS: 33185.3029935\n",
      "LOSS: 33183.3084599\n",
      "LOSS: 33181.3286594\n",
      "LOSS: 33179.3772571\n",
      "LOSS: 33177.4680177\n",
      "LOSS: 33175.6079136\n",
      "LOSS: 33173.8029762\n",
      "LOSS: 33172.0569959\n",
      "LOSS: 33170.3736\n",
      "LOSS: 33168.7542004\n",
      "LOSS: 33167.1993465\n",
      "LOSS: 33165.7090577\n",
      "LOSS: 33164.2826779\n",
      "LOSS: 33162.9192388\n",
      "LOSS: 33161.6172107\n",
      "LOSS: 33160.3747783\n",
      "LOSS: 33159.1900333\n",
      "LOSS: 33158.060913\n",
      "LOSS: 33156.9851921\n",
      "LOSS: 33155.9609984\n",
      "LOSS: 33154.9860242\n",
      "LOSS: 33154.0579008\n",
      "LOSS: 33153.174231\n",
      "LOSS: 33152.3327571\n",
      "LOSS: 33151.531413\n",
      "LOSS: 33150.7682635\n",
      "LOSS: 33150.0414978\n",
      "LOSS: 33149.3493542\n",
      "LOSS: 33148.6901369\n",
      "LOSS: 33148.0623431\n",
      "LOSS: 33147.4644111\n",
      "LOSS: 33146.8948675\n",
      "LOSS: 33146.3523399\n",
      "LOSS: 33145.83557\n",
      "LOSS: 33145.34328\n",
      "LOSS: 33144.8743032\n",
      "LOSS: 33144.4275101\n",
      "LOSS: 33144.0018284\n",
      "LOSS: 33143.5962472\n",
      "LOSS: 33143.2098123\n",
      "LOSS: 33142.8416193\n",
      "LOSS: 33142.4908225\n",
      "LOSS: 33142.1565757\n",
      "LOSS: 33141.8381058\n",
      "LOSS: 33141.5346723\n",
      "LOSS: 33141.2455581\n",
      "LOSS: 33140.9700792\n",
      "LOSS: 33140.7075744\n",
      "LOSS: 33140.4574554\n",
      "LOSS: 33140.2191413\n",
      "LOSS: 33139.9920586\n",
      "LOSS: 33139.7756676\n",
      "LOSS: 33139.5694655\n",
      "LOSS: 33139.3729862\n",
      "LOSS: 33139.1857721\n",
      "LOSS: 33139.0074107\n",
      "LOSS: 33138.8375045\n",
      "LOSS: 33138.6756696\n",
      "LOSS: 33138.5215381\n",
      "LOSS: 33138.3747495\n",
      "LOSS: 33138.2349535\n",
      "LOSS: 33138.1018118\n",
      "LOSS: 33137.9750124\n",
      "LOSS: 33137.854256\n",
      "LOSS: 33137.7392578\n",
      "LOSS: 33137.6297435\n",
      "LOSS: 33137.5254516\n",
      "LOSS: 33137.426132\n",
      "LOSS: 33137.3315445\n",
      "LOSS: 33137.2414635\n",
      "LOSS: 33137.155672\n",
      "LOSS: 33137.0739615\n",
      "LOSS: 33136.9961309\n",
      "LOSS: 33136.9221906\n",
      "LOSS: 33136.8518886\n",
      "LOSS: 33136.7850787\n",
      "LOSS: 33136.7216102\n",
      "LOSS: 33136.6613583\n",
      "LOSS: 33136.604187\n",
      "LOSS: 33136.5499533\n",
      "LOSS: 33136.4985081\n",
      "LOSS: 33136.4497023\n",
      "LOSS: 33136.4033871\n",
      "LOSS: 33136.3594206\n",
      "LOSS: 33136.3176693\n",
      "LOSS: 33136.2780073\n",
      "LOSS: 33136.2403166\n",
      "LOSS: 33136.2044877\n",
      "LOSS: 33136.1704186\n",
      "LOSS: 33136.1380127\n",
      "LOSS: 33136.1071794\n",
      "LOSS: 33136.0778336\n",
      "LOSS: 33136.0498958\n",
      "LOSS: 33136.0232911\n",
      "LOSS: 33135.9979499\n",
      "LOSS: 33135.9738064\n",
      "LOSS: 33135.9507993\n",
      "LOSS: 33135.9288719\n",
      "LOSS: 33135.9079689\n",
      "LOSS: 33135.8880392\n",
      "LOSS: 33135.8690357\n",
      "LOSS: 33135.8509145\n",
      "LOSS: 33135.8336339\n",
      "LOSS: 33135.817155\n",
      "LOSS: 33135.8014406\n",
      "LOSS: 33135.7864555\n",
      "LOSS: 33135.7721666\n",
      "LOSS: 33135.7585422\n",
      "LOSS: 33135.7455525\n",
      "LOSS: 33135.7331687\n",
      "LOSS: 33135.7213635\n",
      "LOSS: 33135.7101107\n",
      "LOSS: 33135.699385\n",
      "LOSS: 33135.6891623\n",
      "LOSS: 33135.6794196\n",
      "LOSS: 33135.6701347\n",
      "LOSS: 33135.6612862\n",
      "LOSS: 33135.6528539\n",
      "LOSS: 33135.6448183\n",
      "LOSS: 33135.6371608\n",
      "LOSS: 33135.6298637\n",
      "LOSS: 33135.62291\n",
      "LOSS: 33135.6162836\n",
      "LOSS: 33135.609969\n",
      "LOSS: 33135.6039516\n",
      "LOSS: 33135.5982171\n",
      "LOSS: 33135.5927523\n",
      "LOSS: 33135.5875444\n",
      "LOSS: 33135.5825812\n",
      "LOSS: 33135.5778517\n",
      "LOSS: 33135.5733449\n",
      "LOSS: 33135.5690503\n",
      "LOSS: 33135.5649577\n",
      "LOSS: 33135.5610576\n",
      "LOSS: 33135.557341\n",
      "LOSS: 33135.5537993\n",
      "LOSS: 33135.5504243\n",
      "LOSS: 33135.5472081\n",
      "LOSS: 33135.5441434\n",
      "LOSS: 33135.541223\n",
      "LOSS: 33135.5384402\n",
      "LOSS: 33135.5357884\n",
      "LOSS: 33135.5332616\n",
      "LOSS: 33135.5308539\n",
      "LOSS: 33135.5285596\n",
      "LOSS: 33135.5263735\n",
      "LOSS: 33135.5242903\n",
      "LOSS: 33135.5223053\n",
      "LOSS: 33135.5204137\n",
      "LOSS: 33135.5186113\n",
      "LOSS: 33135.5168937\n",
      "LOSS: 33135.515257\n",
      "LOSS: 33135.5136974\n",
      "LOSS: 33135.5122111\n",
      "LOSS: 33135.5107949\n",
      "LOSS: 33135.5094452\n",
      "LOSS: 33135.5081591\n",
      "LOSS: 33135.5069334\n",
      "LOSS: 33135.5057655\n",
      "LOSS: 33135.5046524\n",
      "LOSS: 33135.5035917\n",
      "LOSS: 33135.5025809\n",
      "LOSS: 33135.5016176\n",
      "[ 0.          3.03903531  3.86766278 ...,  0.          0.31277757\n",
      "  0.79587699]\n"
     ]
    }
   ],
   "source": [
    "newModel.fit()\n",
    "print newModel.W\n",
    "L2 = newModel.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 740 2627 2585 ..., 2544  358  973]\n"
     ]
    }
   ],
   "source": [
    "L2 = newModel.W\n",
    "# Extract top 10 features\n",
    "m2 = L2.argsort()\n",
    "print m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2468  933 1412 1835  811  358 2544  992 2664  973]\n"
     ]
    }
   ],
   "source": [
    "top10 = m[-10:]\n",
    "print top10\n",
    "less10 = m[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print fDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 973 2664  992 2544  358  811 1835 1412  933 2468]\n",
      "[ 536   94 1544 2042  446 1721  392  439 2585  740]\n"
     ]
    }
   ],
   "source": [
    "t10 = top10[::-1]\n",
    "print t10\n",
    "l10 = less10[::-1]\n",
    "print l10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holds',\n",
       " 'rest',\n",
       " 'banana',\n",
       " 'sparkler',\n",
       " 'supported',\n",
       " 'flavors enriched',\n",
       " 'semillon',\n",
       " 'liqueur',\n",
       " 'cherry berry',\n",
       " 'earns']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fDF['featureID'][l10].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TOP 10 Features---\n",
      "1 spearmint\n",
      "2 huge\n",
      "3 lifesaver\n",
      "4 big\n",
      "5 stars\n",
      "6 ageability\n",
      "7 lemony\n",
      "8 truly\n",
      "9 acidity provides\n",
      "10 apricots\n"
     ]
    }
   ],
   "source": [
    "# 4.4.2\n",
    "print '---TOP 10 Features---'\n",
    "index = 0\n",
    "for i in fDF['featureID'][t10]:\n",
    "    print index+1, i\n",
    "    index += 1\n",
    "    pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Least 10 Features---\n",
      "1 holds\n",
      "2 rest\n",
      "3 banana\n",
      "4 sparkler\n",
      "5 supported\n",
      "6 flavors enriched\n",
      "7 semillon\n",
      "8 liqueur\n",
      "9 cherry berry\n",
      "10 earns\n"
     ]
    }
   ],
   "source": [
    "print '---Least 10 Features---'\n",
    "index = 0\n",
    "for i in fDF['featureID'][l10]:\n",
    "    print index+1, i\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
